{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from pyspark import SparkConf,SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "from pyspark import sql\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "\n",
    ":\n",
    "\n",
    "\n",
    "conf = SparkConf().setMaster(\"local[20]\").setAppName(\"hw\")\n",
    "#sc = SparkContext(conf = conf)\n",
    "sc = SparkContext()\n",
    "sqlContext = sql.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").option(\"inferschema\", \"true\").load(\"/data/MSA_8050_Spring_18/proj09/final_merged_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "li=['business_name',\n",
    " 'neighborhood',\n",
    " 'address','postal_code',\n",
    " 'latitude',\n",
    " 'longitude','is_open',\n",
    " 'categories','review_date','user_name','yelping_since',\n",
    " 'friends',\n",
    " 'user_useful',\n",
    " 'user_funny',\n",
    " 'user_cool',\n",
    " 'fans',\n",
    " 'elite', 'compliment_hot',\n",
    " 'compliment_more',\n",
    " 'compliment_profile',\n",
    " 'compliment_cute',\n",
    " 'compliment_list',\n",
    " 'compliment_note',\n",
    " 'compliment_plain',\n",
    " 'compliment_cool',\n",
    " 'compliment_funny',\n",
    " 'compliment_writer',\n",
    " 'compliment_photos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in li:\n",
    "    df=df.drop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.select(['bus_business_id','review_count1']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"review_count1\",\"bus_review_count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pyspark.sql.functions as f\n",
    "df = df.withColumn('index', f.monotonically_increasing_id())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sort ascending and take first 100 rows for df1\n",
    "df1 = df.sort('index').limit(100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df=df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bus_business_id',\n",
       " 'city',\n",
       " 'state',\n",
       " 'stars',\n",
       " 'bus_review_count',\n",
       " 'review_id',\n",
       " 'user_id',\n",
       " 'business_id',\n",
       " 'review_stars',\n",
       " 'text',\n",
       " 'review_useful',\n",
       " 'review_funny',\n",
       " 'review_cool',\n",
       " 'user_user_id',\n",
       " 'review_count',\n",
       " 'average_stars']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df=df.drop('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(city=u'Las Vegas', Reviews=6040013),\n",
       " Row(city=u'Phoenix', Reviews=709873),\n",
       " Row(city=u'Scottsdale', Reviews=341888),\n",
       " Row(city=u'Toronto', Reviews=301586),\n",
       " Row(city=u'Henderson', Reviews=259118)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy('city').agg(sum('bus_review_count').alias('Reviews')).sort(col('Reviews').desc()).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_top_city=df.where(df.city.isin(['Phoenix','Las Vegas','Scottsdale','Toronto','Henderson']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdd_top_city=df_top_city.rdd.map(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kingale1/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words =  rdd_top_city.map(lambda x:(x[1], x[9].encode(\"utf-8\").lower().translate(None,string.punctuation).strip()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwrds = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = words.reduceByKey(lambda x,y:x+y).map(lambda x:(x[0],x[1].split(\" \"))).map(lambda x:(x[0],{i:x[1].count(i) for i in set(x[1])}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = X.map(lambda x:(x[0],OrderedDict(sorted(x[1].items(), key = lambda y:y[1], reverse = True))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_11 = Z.map(lambda x: (x[0], [i for i in x[1] if i not in stopwrds][:11]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toronto : ['place', 'food', 'good', 'great', 'like', 'one', 'service', 'really', 'would', 'get']\n",
      "Phoenix : ['place', 'food', 'good', 'great', 'like', 'get', 'time', 'service', 'one', 'would']\n",
      "Scottsdale : ['great', 'place', 'food', 'good', 'service', 'like', 'time', 'would', 'get', 'one']\n",
      "Las Vegas : ['good', 'food', 'place', 'great', 'like', 'get', 'time', 'service', 'one', 'would']\n",
      "Henderson : ['food', 'good', 'like', 'great', 'place', 'time', 'get', 'really', 'one', 'service']\n"
     ]
    }
   ],
   "source": [
    "for k,v in top_11.collect():\n",
    "    print '{0} : {1}'.format(k,list(v)[1:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark 1.6.1 - Cluster",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
